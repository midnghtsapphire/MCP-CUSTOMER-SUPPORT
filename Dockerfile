FROM node:14
WORKDIR /usr/src/app
COPY package*.json ./
RUN npm install
COPY . .
RUN npm run build
EXPOSE 3000
CMD [ "npm", "start" ]
### README.md
# MCT-CUSTOMER-SUPPORT MCP Server
## Description
This project contains the MCP Server implementation for a customer support module, allowing AI tools to access customer data.
## Setup
Install dependencies:
npm install
Build the project:
npm run build
Run the server:
npm start
## Usage
The server starts on the default port 3000, and provides an MCP interface for customer support tools.
This setup includes TypeScript for type-safety, Node.js for the server environment, and an MCP server module pattern for interfacing with AI platforms. Adjust paths and configurations as needed depending on your actual database and environment setup.
---
## ‚ö†Ô∏è Failed Responses
- **qwen/qwen-2.5-coder-32b:** Error: 400 - {"error":{"message":"qwen/qwen-2.5-coder-32b is not a valid model ID","code":400},"user_id":"user_34BajsuC4iIXxoAtGeO2pzlKkKd"}
- **deepseek/coder:** Error: 400 - {"error":{"message":"deepseek/coder is not a valid model ID","code":400},"user_id":"user_34BajsuC4iIXxoAtGeO2pzlKkKd"}
- **meta-llama/llama-3.3-70b:** Error: 400 - {"error":{"message":"meta-llama/llama-3.3-70b is not a valid model ID","code":400},"user_id":"user_34BajsuC4iIXxoAtGeO2pzlKkKd"}
---
## üìä Synthesis
**Overview:** 2 models provided responses to the prompt.
**Common Themes:**
- All models addressed the core question
- Responses varied in depth and approach
**Response Lengths:**
- Longest: claude-3.5-sonnet:coding (8,153 characters)
- Shortest: gpt-4-turbo (3,780 characters)
**Quality Notes:**
- Review each response above for accuracy and completeness
- Consider combining insights from multiple responses
- Premium models (GPT-4, Claude Opus) typically provide more depth
**Recommendation:**
Read all responses and synthesize the best elements from each. Different models excel at different aspects - combine their strengths.
---
## üí∞ Cost Summary
**Total Tokens:** 11,984
**Estimated Cost:** $0.0360